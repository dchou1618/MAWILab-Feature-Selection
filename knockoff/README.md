# Causal Inference Notes

**Causal Inference Without Models**
1. In the case of discrete outcomes, if we can access the outcome of a subject with and without treatment *A*, then we can access whether there was a causal effect. With notation, we can define what a causal effect on an individual means: Suppose that $Y^{a=1}$ is the outcome of survival for a subject if they did receive treatment $A$. Then $Y^{a=1} \neq Y^{a=0}$ indicates a causal effect. Individual causal effects cannot be observed because of missing data from one of the two $Y$ counterfactual outcomes. Our *assumption* with counterfactual outcomes is that they cannot interfere with one another. Otherwise, outcomes would not be well-defined and would need to be qualified with statements indicating "no interaction between units", for instance.

2. Instead of comparing discrete outcomes of individual causal effects, we can compare probabilities of the same outcome occurring after receiving or not receiving a treatment (an average treatment effect). By definition, an average treatment effect is present if $P[Y^{a=1}=1] \neq P[Y^{a=0}=1]$. Our null hypothesis is that the probabilities are equal and there is *no causal effect*. Population average is usually denoted by expectation, so we would say there's an average causal effect if $E[Y^{a=1}] \neq E[Y^{a=0}]$ (note: $E[Y^{a=1}]=0 * P[Y^{a=1}=0]+P[Y^{a=1}=1]=P[Y^{a=1}=1]$). When there is no causal effect on any individual, this supports a *sharp causal null hypothesis* and implies the null hypothesis of no average causal effect. A population causal effect can be any contrast of marginal distribution functions for distinct actions or treatments. The causal risk difference is the average causal effects $Y^{a=1}-Y^{a=0}$. However, the causal risk ratio $Y^{a=1}/Y^{a=0}$ is not a measure of average causal effects, just causal effect in the population. 

3. Example: Supposed we have a population of 100 million people. If we have a causal risk difference (difference in probabilities) of -0.1 between people dying after 5 years without treatment and with treatment, we know that treating 100 million patients would result in 10 million fewer deaths. The average number of people to treat to reduce the number of $Y=1$ (deaths) is the number needed to treat (NNT) = $-1/(P[Y^{a=1}=1]-P[Y^{a=0}=1])$.

4. Introducing random variability, suppose that a random sample was drawn from a nearly infinite population and we found slight differences between the probabilities of $P[Y^{a=1}=1]$ and $P[Y^{a=0}=1]$. Those differences could be from randomness from sampling, so the probabilities are estimators - the estimated probability is a consistent estimator if P_hat[Y^{a}=1]-P[Y^{a}=1] approaches 0 with more subjects. We cannot ascertain with certianty that there is a causal effect in the population without a statistical procedure to evaluate the null hypothesis. 

5. For nondeterministic outcomes, the mean outcome under treatment $A$ is $E[Y^{a}] = \sum_{y} y * p_{Y^{a}}(y)$ over all possible outcomes of $Y^{a}$. The probability mass function is $p_{Y^{a}}(\dot) = E[Q_{Y^{a}}(\dot)]$ and $Q_{Y^{a}}(y)$ is the random probability of having outcome $y$ for treatment $A$. $Q_{Y^{a=1}}(1) = 0.9$ denotes the random probability (0.9) of someone receiving treatment $A$, then dying. A nondeterministic definition of causal effect is a generalization of the deterministic definition where $\Omega_{Y^{a}}(\dot)$ is a CDF now taking on values 0 to 1. The average counterfactual outcome $E[Y^{a}]$ equals $E[E[Y^{a}|\Omega_{Y^{a}}(\dot)]] = E[\int y d\Omega_{Y^{a}}(y)] = \int y dE[\Omega_{Y^{a}}(y)] = \int y dF_{Y^{a}}(y) = \int y dF_{Y^{a}}(y)$ where $F_{Y^{a}}(\dot) = E[\Omega_{Y^{a}_i}]$.

6. Outcome $Y$ and $A$ are independent if proportion of y outcome with or without treatment $A$ - P[Y=1|A=1] = P[Y=1|A=0]. Causation implies a difference in outcomes each subject taking and not taking the treatment while association is picking different subjects and taking the observed difference in expected outcomes between someone who took the treatment and another who didn't. Questions about causation are concerned with what if while association deals with questions about the actual world.

7. In randomized experiments, we want to have missing data with counterfactual outcomes occur by chance. Effect measures could then be computed more rigorously and consistently estimated. **Exchangeability** is that the risk of outcome $Y=1$ in the treatment group would have been the same in the untreated group if they received the same treatment. Namely, $Y^{a}$ is independent of $A$ for all $a$ or $P[Y^{a}=1|A=1]=P[Y^{a}=1|A=0]$. Randomization can allow for exchangeability. Formally, suppose that all possible treatments are $\{a,a^{'},a^{''},...\}$ and counterfactual outcomes are $\{Y^{a},Y^{a^{'}},...\}$. **Full Exchangeability** =  $Y^{A}$ independent of $A$. For dichotomous treatment and outcome, we can have **mean exchangeability**: $E[Y^{a}|A=1]=E[Y^{a}|A=0]$. For a continuous outcome, we would have mean exchangeability be: $E[Y^{a}|A=a']=E[Y^{a}]$. Mean exchangeability may not indicate full exchangeability because distributional parameters besides the mean may not be independent.

8. In crossover experiments, we may want to observe the outcomes of two different treatments at time steps $t=0$ and $t=1$ under these conditions: (1) No carryover effects from the treatment (2) individual causal effect does not change over time (3) The counterfactual outcome under no treatment does not depend on time. 

9. Consider two experimental designs: (1) we randomly select 65% of individuals from a population and transplant a new heart to each of them (13/20 treated individuals) or (2) classify all individuals as being in critical or noncritical condition and have assign treatment to 75% of critical & 25% of noncritical. **Conditional randomization** is an experimental design that uses randomization probabilities that depend on the condition groups of the patients (critical vs. noncritical conditions) - conditional randomization can be multiple marginal randomizations applied to data sub-groups. **Marginally randomized experiments** refer to those mentioned in (1) that apply same randomization probability to all subjects. Conditional randomization does not guarantee marginal exchangeability, but it does **ensure conditional exchangeability** - $Y^{a}$ independent of A given subgroup L. Pr[Y^{a=1}|A=1] = Pr[Y^{a=0}|A=0]$ and $Y^{a} independent of A for all a. A marginally randomized experiment may not result in exchangeability between untreated and treated groups because every group may have a different number of people with bad prognosis.

**Causal Inference With Models**

1. Why use models? When we restrict ourselves to estimators of the data, we reach challenges with undefined estimations.

2. Variable selection for causal inference may introduce biases in the effect estimate. Suppose we want to unbiasedly measure the average treatment effect $A$ on outcome $Y$: $E[Y^{a=1}]-E[Y^{a=0}]$. Covariate adjustment would be to eliminate as much confounding as possible using the information in the variables $X$. Adjustments, to account for confounding, of all variables may induce bias.
