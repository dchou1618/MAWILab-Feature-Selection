{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Granger Causality and Inverse Probability Weighting\n",
    "**Learning Objectives**\n",
    "* Protocol Buffers in Python\n",
    "* Imputing Missing Data using semi-supervised learning with forecast model - just as with stock markets, unexpected events may occur. Although they may not fully be captured in the intended ARIMA model's noise terms, it is done for imputation so protocol buffers types within messages may be used.\n",
    "* Granger Causality Implementation\n",
    "* Making causal claims - difference in expected outcomes - using inverse probability weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from pandas.plotting import autocorrelation_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacksData = pd.read_csv('./malicious_dataset.csv') \n",
    "normalData = pd.read_csv('./normal_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalData['label'] = 'normal' # adds label column to be compatible with attacksData when concatenating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalAndAttack = pd.concat([normalData,attacksData])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normalAndAttack = normalAndAttack.rename(columns={s: (s.replace(\".\",\"_\")) for s in list(normalAndAttack.columns)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noting less meaningful features: ip_flags_mf, ip_tos, ip_flags_rb, ip_frag_offset - some were all NaN or \n",
    "# mostly NaN with only one other possibility.\n",
    "# only 4.0.\n",
    "# ip_version\n",
    "# ip_hdr_len\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normalAndAttack = normalAndAttack.drop(columns=['ip_flags_mf', 'ip_tos', \n",
    "                                                'ip_flags_rb', 'ip_frag_offset',\n",
    "                                                \"ip_version\",\"ip_hdr_len\",\n",
    "                                               \"frame_info_encap_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hmms consider observations over time steps, but they look into the probability of \n",
    "# hidden tags given the observations. Here, we have a time-series. \n",
    "# Here, neural networks are a possibility, but it's a black box approach and convergence \n",
    "# is towards a local optima. Convergence may also be slow. One can do a naive mean, a naive equality\n",
    "# to the previous value or seasonal naive model for time-series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttl - time to live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = dict()\n",
    "months[\"Jan\"] = 1\n",
    "months[\"Feb\"] = 2\n",
    "months[\"Mar\"] = 3\n",
    "months[\"Apr\"] = 4\n",
    "months[\"May\"] = 5\n",
    "months[\"Jun\"] = 6\n",
    "months[\"Jul\"] = 7\n",
    "months[\"Aug\"] = 8\n",
    "months[\"Sep\"] = 9\n",
    "months[\"Oct\"] = 10\n",
    "months[\"Nov\"] = 11\n",
    "months[\"Dec\"] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSS_VAL is the maximum segment size under the options \n",
    "# field of TCP header that informs the largest \n",
    "# amount of data in bytes that a machine can receive in a single TCP segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting categorical attributes\n",
    "# ip_flags\n",
    "# ip_flags_df\n",
    "# ip_proto\n",
    "# tcp_flags_fin\n",
    "# tcp_flags_syn\n",
    "# tcp_flags_reset\n",
    "# tcp_flags_push\n",
    "# tcp_flags_ack\n",
    "# tcp_flags_urg\n",
    "# tcp_flags_cwr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majorityVoteVal(col):\n",
    "    counts = dict()\n",
    "    maxCount, maxVal = 0, None\n",
    "    for val in col:\n",
    "        if counts.get(val) == None:\n",
    "            if 1 >= maxCount:\n",
    "                maxCount = 1\n",
    "                maxVal = val\n",
    "            counts[val] = 1\n",
    "        else:\n",
    "            if counts[val]+1 >= maxCount:\n",
    "                maxCount = counts[val]+1\n",
    "                maxVal = val\n",
    "            counts[val] += 1\n",
    "    return maxVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nas in these: tcp_srcport, tcp_dstport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valueNaNs = dict()\n",
    "for col in [\"ip_flags\", \"ip_flags_df\", \"ip_proto\", \n",
    "            \"tcp_flags_fin\", \"tcp_flags_syn\", \"tcp_flags_reset\",  \n",
    "            \"tcp_flags_push\", \"tcp_flags_ack\", \"tcp_flags_urg\",\n",
    "            \"tcp_flags_cwr\",\"tcp_urgent_pointer\"]:\n",
    "    val = majorityVoteVal(list(normalAndAttack[col].dropna()))\n",
    "    valueNaNs[col] = val\n",
    "newNormalAndAttack = normalAndAttack.fillna(value=valueNaNs)\n",
    "#newNormalAndAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "newNormalAndAttack2 = newNormalAndAttack.dropna(subset=['ip_src', 'ip_dst','tcp_srcport','tcp_dstport'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "newNormalAndAttack2 = newNormalAndAttack2.drop(columns=['ip_proto','eth_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30032444822329"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliest=datetime.datetime.strptime(\"2019-11-21 02:00:00.313671\", '%Y-%m-%d %H:%M:%S.%f')\n",
    "s = \"Nov 2, 2020 16:20:45.136949\"\n",
    "def formatTime(s):\n",
    "    items = s.split(\" \")\n",
    "    modified_items = list(filter(lambda x: x != '', items))\n",
    "    day = modified_items[1][:len(modified_items[1])-1]\n",
    "    if len(modified_items[1]) == 2:\n",
    "        day = \"0\" + day\n",
    "    month = str(months[modified_items[0]])\n",
    "    if len(month) == 1:\n",
    "        month = \"0\" + month\n",
    "    hours = modified_items[3]\n",
    "    newdate = modified_items[2]+\"-\"+ month + \"-\" + day + \" \"+hours[:len(hours)-3]\n",
    "    dateTimeDate =  datetime.datetime.strptime(newdate, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    def timestamp_microsecond(currDateTime):\n",
    "        diff = currDateTime - earliest\n",
    "        return (diff.days * 86400 + diff.seconds) * 10**6 + diff.microseconds\n",
    "    return timestamp_microsecond(dateTimeDate)\n",
    "formatTime(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newNormalAndAttack2 = newNormalAndAttack2.assign(frame_info_time = newNormalAndAttack2[\"frame_info_time\"].map(formatTime))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['frame_info_time', 'frame_info_time_epoch', 'frame_info_number',\n",
       "       'frame_info_len', 'frame_info_cap_len', 'ip_id', 'ip_flags',\n",
       "       'ip_flags_df', 'ip_ttl', 'ip_checksum', 'ip_src', 'ip_dst', 'ip_len',\n",
       "       'ip_dsfield', 'tcp_srcport', 'tcp_dstport', 'tcp_seq', 'tcp_ack',\n",
       "       'tcp_len', 'tcp_hdr_len', 'tcp_flags', 'tcp_flags_fin', 'tcp_flags_syn',\n",
       "       'tcp_flags_reset', 'tcp_flags_push', 'tcp_flags_ack', 'tcp_flags_urg',\n",
       "       'tcp_flags_cwr', 'tcp_window_size', 'tcp_checksum',\n",
       "       'tcp_urgent_pointer', 'tcp_options_mss_val', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newNormalAndAttack2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24762044823278"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = datetime.datetime.strptime(\"2020-09-02 16:20:45.136949\",'%Y-%m-%d %H:%M:%S.%f')\n",
    "p=datetime.datetime.strptime(\"2019-11-21 02:00:00.313671\", '%Y-%m-%d %H:%M:%S.%f')\n",
    "def timestamp_microsecond(utc):\n",
    "    diff = utc - p\n",
    "    assert diff.resolution == datetime.timedelta(microseconds=1)\n",
    "    return (diff.days * 86400 + diff.seconds) * 10**6 + diff.microseconds\n",
    "timestamp_microsecond(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(len(newNormalAndAttack2[\"ip_flags\"]))\n",
    "#len(newNormalAndAttack2[\"ip_flags\"].dropna())\n",
    "#newNormalAndAttack2[\"tcp_urgent_pointer\"].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelTypes = list(newNormalAndAttack2[\"label\"].unique())\n",
    "def getNumericLabels(label):\n",
    "    return labelTypes.index(label)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['normal', 'nmap_null', 'nmap_connect', 'zmap', 'nmap_window', 'masscan', 'hping_syn', 'unicorn_null', 'unicorn_syn', 'nmap_xmas', 'nmap_syn', 'unicorn_conn', 'unicorn_xmas', 'nmap_ack', 'hping_fin', 'nmap_maimon', 'hping_null', 'hping_xmas', 'hping_ack', 'nmap_fin', 'unicorn_fxmas']\n"
     ]
    }
   ],
   "source": [
    "print(labelTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "newNormalAndAttack2 = newNormalAndAttack2.assign(label = newNormalAndAttack2[\"label\"].map(getNumericLabels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newNormalAndAttack2['tcp_flags_reset'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = newNormalAndAttack2.to_csv(\"portScan_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#newNormalAndAttack.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = newNormalAndAttack2.sample(100)\n",
    "G = nx.from_pandas_edgelist(df, source='ip_src', \n",
    "                            target='ip_dst',edge_attr=True,\n",
    "                            create_using=nx.DiGraph())\n",
    "H = G.to_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx.draw_circular(G,with_labels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1600\"\n",
       "            height=\"1600\"\n",
       "            src=\"g.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fc9401fe850>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Network(height=1600,width=1600,notebook=True)\n",
    "g.toggle_hide_edges_on_drag(True)\n",
    "g.barnes_hut()\n",
    "# from_nx only accepts undirected graphs\n",
    "g.from_nx(H)\n",
    "g.show(\"g.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(set(newNormalAndAttack[\"ip_src\"])).intersection(set(newNormalAndAttack[\"ip_dst\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values in Time Series\n",
    "* As with any missing values, one can (1) impute the data or (2) remove the records. \n",
    "* Imputation occurs in RStudio - Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# added again for convenience\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "updatedPortScanDf = pd.read_csv(\"newPortData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updatedPortScanDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "updatedPortScanDf = updatedPortScanDf.drop(columns=['X','Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updatedPortScanDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import portData_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_info_time</th>\n",
       "      <th>frame_info_time_epoch</th>\n",
       "      <th>frame_info_number</th>\n",
       "      <th>frame_info_len</th>\n",
       "      <th>frame_info_cap_len</th>\n",
       "      <th>ip_id</th>\n",
       "      <th>ip_flags</th>\n",
       "      <th>ip_flags_df</th>\n",
       "      <th>ip_ttl</th>\n",
       "      <th>ip_checksum</th>\n",
       "      <th>...</th>\n",
       "      <th>tcp_flags_reset</th>\n",
       "      <th>tcp_flags_push</th>\n",
       "      <th>tcp_flags_ack</th>\n",
       "      <th>tcp_flags_urg</th>\n",
       "      <th>tcp_flags_cwr</th>\n",
       "      <th>tcp_window_size</th>\n",
       "      <th>tcp_checksum</th>\n",
       "      <th>tcp_urgent_pointer</th>\n",
       "      <th>tcp_options_mss_val</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.574312e+09</td>\n",
       "      <td>7</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>46834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "      <td>12832</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>61355</td>\n",
       "      <td>0</td>\n",
       "      <td>17055.139055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2481.0</td>\n",
       "      <td>1.574312e+09</td>\n",
       "      <td>12</td>\n",
       "      <td>551</td>\n",
       "      <td>66</td>\n",
       "      <td>3793</td>\n",
       "      <td>16384</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>13960</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>252</td>\n",
       "      <td>60933</td>\n",
       "      <td>0</td>\n",
       "      <td>16923.056473</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2556.0</td>\n",
       "      <td>1.574312e+09</td>\n",
       "      <td>14</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>16384</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>12472</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4677</td>\n",
       "      <td>18651</td>\n",
       "      <td>0</td>\n",
       "      <td>16738.109830</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3197.0</td>\n",
       "      <td>1.574312e+09</td>\n",
       "      <td>15</td>\n",
       "      <td>68</td>\n",
       "      <td>66</td>\n",
       "      <td>8559</td>\n",
       "      <td>16384</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>64767</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>7590</td>\n",
       "      <td>0</td>\n",
       "      <td>16507.535890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3273.0</td>\n",
       "      <td>1.574312e+09</td>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>40274</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>18914</td>\n",
       "      <td>0</td>\n",
       "      <td>16237.596014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame_info_time  frame_info_time_epoch  frame_info_number  frame_info_len  \\\n",
       "0              0.0           1.574312e+09                  7              54   \n",
       "1           2481.0           1.574312e+09                 12             551   \n",
       "2           2556.0           1.574312e+09                 14              94   \n",
       "3           3197.0           1.574312e+09                 15              68   \n",
       "4           3273.0           1.574312e+09                 16              54   \n",
       "\n",
       "   frame_info_cap_len  ip_id  ip_flags  ip_flags_df  ip_ttl  ip_checksum  ...  \\\n",
       "0                  54  46834         0            0     247        12832  ...   \n",
       "1                  66   3793     16384            1      56        13960  ...   \n",
       "2                  94      0     16384            1      59        12472  ...   \n",
       "3                  66   8559     16384            1      55        64767  ...   \n",
       "4                  54  54321         0            0     244        40274  ...   \n",
       "\n",
       "  tcp_flags_reset tcp_flags_push  tcp_flags_ack  tcp_flags_urg  tcp_flags_cwr  \\\n",
       "0               0              0              0              0              0   \n",
       "1               0              1              1              0              0   \n",
       "2               0              0              1              0              0   \n",
       "3               0              1              1              0              0   \n",
       "4               0              0              0              0              0   \n",
       "\n",
       "   tcp_window_size  tcp_checksum  tcp_urgent_pointer  tcp_options_mss_val  \\\n",
       "0             1024         61355                   0         17055.139055   \n",
       "1              252         60933                   0         16923.056473   \n",
       "2             4677         18651                   0         16738.109830   \n",
       "3              115          7590                   0         16507.535890   \n",
       "4            65535         18914                   0         16237.596014   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updatedPortScanDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portDataFile: Could not open file.  Creating a new one.\n"
     ]
    }
   ],
   "source": [
    "def addFrameExamples(dataframe, filename):\n",
    "    # some borrowed from https://developers.google.com/protocol-buffers/docs/pythontutorial\n",
    "    # read the existing \n",
    "    newPortData = portData_pb2.portDataFrame()\n",
    "    try:\n",
    "        f = open(filename, \"rb\")\n",
    "        newPortData.ParseFromString(f.read())\n",
    "        f.close()\n",
    "    except IOError:\n",
    "        # then no file available\n",
    "        print(filename + \": Could not open file.  Creating a new one.\")\n",
    "    cols = list(dataframe.columns)\n",
    "    for index, row in dataframe.iterrows():\n",
    "        example = newPortData.examples.add()\n",
    "        for i in range(len(cols)):\n",
    "            exec(\"example.{} = row[{}]\".format(cols[i], i))\n",
    "        # 42 being the fixed number of columns - attributes\n",
    "        \n",
    "    f = open(filename, \"wb\")\n",
    "    f.write(newPortData.SerializeToString())\n",
    "    f.close()\n",
    "\n",
    "addFrameExamples(updatedPortScanDf,\"portDataFile\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install read-protobuf\n",
    "from read_protobuf import read_protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "portDataFrame = portData_pb2.portDataFrame()\n",
    "protoDf = read_protobuf('portDataFile', portDataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "protoDf = protoDf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000e+00, 1.0000e+00, 1.0000e+01, 4.6335e+04, 4.0571e+04,\n",
       "       2.5600e+02])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protoDf[\"tcp_urgent_pointer\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protocol Buffers\n",
    "A Protocol Buffer is one among many data serialization methods such as CSV, JSON, or XML that \n",
    "has advantages in datatype support defined in the .proto file and standardization maintained\n",
    "by Google, but is not intended to be human-readable. The serialization method that \n",
    "results in the most human-readable data is TOML, but it's slower than other serialization\n",
    "methods. There is also less language support with TOML given it was released initially in 2013 \n",
    "and is relatively inchoate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notions of Causality\n",
    "\n",
    "The earliest concept of causality in time-series data was granger causality that suggested the difference\n",
    "between predicting stochastic process $Y$ compared to $X$ given all the information of the \"universe\". \n",
    "Assuming that $X,Y$ are stationary stochastic processes.\n",
    "\n",
    "If removing $X$ reduces the predictive power regarding $Y$, $X$ contains unique information regarding $Y$ so \n",
    "$X$ Granger-causes $Y$.\n",
    "\n",
    "$U_i = (U_{i_1},...,U_{i_{\\infty}})$ contains all the information until time $i$. $\\sigma^2 (Y_i|U_i)$\n",
    "is the variance of predicting $Y_i$ using $U_i$ at time $i$. $\\sigma^2 (Y_i|U_i \\ X_i)$ excludes $X_i$\n",
    "when predicting $Y_i$. \n",
    "\n",
    "If $\\sigma^2 (Y_i|U_i) < \\sigma^2 (Y_i|U_i \\ X_i)$, then $X$ granger-causes $Y$.\n",
    "\n",
    "**A feedback** occurs between $X,Y$ when $X$ granger-causes $Y$ and $Y$ granger-causes $X$.\n",
    "\n",
    "**Practically, we have access to a limited set of observed time series $X$, so we observe $X$ \n",
    "granger-causes $Y$ w.r.t $X$**\n",
    "\n",
    "**Instantaneous causality** occurs between 2 stochastic processes if at time $i$, adding $X_i$\n",
    "helps improve the predicted value $Y_i$. \n",
    "\n",
    "If $\\sigma^2(Y_i|U_i \\cup \\{X_i\\}) < \\sigma^2(Y_i|U_i)$, then there is instantaneous causality between X and Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Probability Weighting (IPW)\n",
    "\n",
    "IPW compensates for underrepresented and oversampled groups by weighting individuals from a particular group by the inverse of the probability of being in that group. Thereby, those in minority groups will be weighed more \n",
    "heavily than those in oversampled groups. \n",
    "\n",
    "The notion of a pseudo-population occurs with \n",
    "\n",
    "The causal estimand is **identifiable** if we have exchangeability  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can look to root cause detection in anomalous time series. This comes from anomalous behavior\n",
    "of one of the continuous variables. Another approach involves directly identifying the causal\n",
    "structures at play with graph search.\n",
    "**SGS/PC Algorithms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "updatedNumericPortScanDf = updatedPortScanDf.drop(columns=[\"ip_src\",\"ip_dst\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we use an \"adjacency list\" representation as a mapping of a feature to every other feature.\n",
    "# (1) This is the initialization of the fully, densely connected graph\n",
    "connectedGraph = dict()\n",
    "numericCols = updatedNumericPortScanDf.columns\n",
    "colsSet = set(numericCols)\n",
    "for col in numericCols:\n",
    "    connectedGraph[col] = colsSet.difference(set([col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) edge elimination occurs when edges are conditionally independent - \n",
    "# test for conditional independence can be under PC Algorithm that \n",
    "# assumes \n",
    "# (3) identifying unshielded colliders - for pairs of variables connected\n",
    "# through a third variable, test conditional independence on third variable.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Granger Causality F-test\n",
    "**With Granger Causality, we can conduct the F-test** by comparing a full model against reduced model.\n",
    "If the null hypothesis is rejected, we say some stochastic process $X$ granger-causes $Y$. This \n",
    "provides insight into how well the previous values of \n",
    "one time series can predict the other.\n",
    "\n",
    "**When doing these analyses, we assuming the causes precede the effect and the cause has\n",
    "unique information about future values of effect**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=1.5328  , p=0.1205  , df_denom=284670, df_num=10\n",
      "ssr based chi2 test:   chi2=15.3296 , p=0.1205  , df=10\n",
      "likelihood ratio test: chi2=15.3292 , p=0.1205  , df=10\n",
      "parameter F test:         F=1.5328  , p=0.1205  , df_denom=284670, df_num=10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{10: ({'ssr_ftest': (1.5328469320571256, 0.12054409934638233, 284670.0, 10),\n",
       "   'ssr_chi2test': (15.329600096050696, 0.12049929983907455, 10),\n",
       "   'lrtest': (15.329187377355993, 0.12051322041755312, 10),\n",
       "   'params_ftest': (1.532846930777425, 0.12054409977629976, 284670.0, 10.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x7fe8c4833700>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x7fe8c4833ca0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0.]])])}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grangercausalitytests(updatedPortScanDf[[\"tcp_options_mss_val\",\"ip_ttl\"]], [10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install fcit\n",
    "# we determine if P(y|x, z) = P(y|z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcit import fcit\n",
    "pvalLenMSS = fcit.test(np.transpose(np.matrix(updatedPortScanDf[\"frame_info_len\"])),\n",
    "                       np.transpose(np.matrix(updatedPortScanDf[\"tcp_options_mss_val\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002389977472441613"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalLenMSS\n",
    "# fcit tests for the null hypothesis that x is independent of y\n",
    "# low p-value, so given x is independent of y, obtaining the observations from the two\n",
    "# vectors or more extreme is very unlikely. \n",
    "# we reject and may consider that x is not independent of y.\n",
    "# another consideration for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGraph = updatedPortScanDf.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02655792990842002"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcit.test(np.transpose(np.matrix(dfGraph[\"frame_info_len\"])),\n",
    "          np.transpose(np.matrix(dfGraph[\"tcp_options_mss_val\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are dependencies from previous iterations - sequential\n",
    "def eliminateEdges(dfGraph,connectedGraph):\n",
    "    def reject(node,neighbor,third=None): \n",
    "        if third is None:\n",
    "            third = np.empty([dfGraph[node].shape[0], 0])\n",
    "        print(node,neighbor)\n",
    "        pval = fcit.test(np.transpose(np.matrix(dfGraph[node])),\n",
    "                       np.transpose(np.matrix(dfGraph[neighbor])), \n",
    "                        third)\n",
    "        if pval < 0.05:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    for node in connectedGraph:\n",
    "        currNeighbors = list(connectedGraph[node])\n",
    "        while len(currNeighbors) != 0: # neighbor is element in a set\n",
    "            neighbor = currNeighbors[0]\n",
    "            if not reject(node,neighbor):\n",
    "                connectedGraph[node].remove(neighbor)\n",
    "                connectedGraph[neighbor].remove(node)\n",
    "            else:\n",
    "                for third in connectedGraph[neighbor]:\n",
    "                    if third != node and reject(node,neighbor,\n",
    "                                                np.transpose(np.matrix(dfGraph[third]))):\n",
    "                        connectedGraph[node].remove(neighbor)\n",
    "                        connectedGraph[neighbor].remove(node)\n",
    "                        break\n",
    "            currNeighbors = currNeighbors[1:]\n",
    "    return connectedGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newGraph = eliminateEdges(dfGraph,connectedGraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
